{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Wrangling<h1>\n",
    "<h2><i>Discovering, Structuring, Cleaning, Enriching, Validating, and Publishing<i><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> What Do You Want to Do? </h2>\n",
    "<a id = 'Data Loading'># 1. Data Loading</a><br>\n",
    "<a id = 'Data Inspection'># 2. Data Inspection</a><br>\n",
    "<a id = 'Data Cleaning'># 3. Data Cleaning</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structured Data Wrangling\n",
    "import numpy as np #working with arrays\n",
    "import pandas as pd #structured data manipulation\n",
    "import matplotlib.pyplot as plt #to visualize the data\n",
    "import seaborn as sns #to visualize the data\n",
    "import scipy.stats #perform statistics\n",
    "import statsmodels.stats #perform descriptive statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools to Explore\n",
    "* [OpenRefine](https://openrefine.org/) - cleaning, transforming, & extending\n",
    "* [Google DataPrep](https://cloud.google.com/dataprep) - visually exploring, cleaning, and preparing structured and unstructured data \n",
    "* [Amazon SageMaker DataWrangler](https://aws.amazon.com/sagemaker/data-wrangler/) - prepare tabular and image data for ML\n",
    "* [Tabula](https://tabula.technology/) - pull tables from PDF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Data Wrangling Steps - GOAL = Prepared, Ideal State for Analysis\n",
    "* General Understanding\n",
    "* Missing Data and Dealing with Incomplete Data\n",
    "* Outliers\n",
    "* Reshaping or Restructuring\n",
    "* Centralizing, Merging Data Shources\n",
    "* Investigate Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading\n",
    "load data from various sources such as CSV files, Excel sheets, databases, etc., into a structured format like Pandas DataFrame\n",
    "\n",
    "*GOAL: How would you make this efficient? and Handle the Most Common Formats & Configurations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "\n",
    "def load_data(source, **kwargs):\n",
    "    \"\"\"\n",
    "    Load data from various sources.\n",
    "\n",
    "    Parameters:\n",
    "        source (str): The source of the data. Supported values: 'csv', 'excel', 'json', 'database'.\n",
    "        **kwargs: Additional keyword arguments depending on the data source.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame (CSV, Excel, Database) or other appropriate data structure (JSON).\n",
    "\n",
    "    Example usage:\n",
    "        # Load CSV data\n",
    "        csv_data = load_data(source='csv', filepath='data.csv')\n",
    "\n",
    "        # Load Excel data\n",
    "        excel_data = load_data(source='excel', filepath='data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "        # Load JSON data\n",
    "        json_data = load_data(source='json', filepath='data.json')\n",
    "\n",
    "        # Load data from a database\n",
    "        database_data = load_data(source='database', db_path='example.db', query='SELECT * FROM table_name')\n",
    "    \"\"\"\n",
    "    supported_sources = ['csv', 'excel', 'json', 'database']\n",
    "    if source not in supported_sources:\n",
    "        raise ValueError(f\"Unsupported data source. Supported sources are: {', '.join(supported_sources)}\")\n",
    "\n",
    "    if source == 'csv':\n",
    "        filepath = kwargs.pop('filepath')\n",
    "        if filepath is None:\n",
    "            raise ValueError(\"CSV filepath must be provided.\")\n",
    "        return pd.read_csv(filepath, **kwargs)\n",
    "\n",
    "    elif source == 'excel':\n",
    "        filepath = kwargs.get('filepath')\n",
    "        if filepath is None:\n",
    "            raise ValueError(\"Excel filepath must be provided.\")\n",
    "        return pd.read_excel(filepath, **kwargs)\n",
    "\n",
    "    elif source == 'json':\n",
    "        filepath = kwargs.get('filepath')\n",
    "        if filepath is None:\n",
    "            raise ValueError(\"JSON filepath must be provided.\")\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "\n",
    "    elif source == 'database':\n",
    "        db_path = kwargs.get('db_path')\n",
    "        if db_path is None:\n",
    "            raise ValueError(\"Database path must be provided.\")\n",
    "        query = kwargs.get('query')\n",
    "        if query is None:\n",
    "            raise ValueError(\"Query must be provided to extract data from the database.\")\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        data = pd.read_sql(query, conn, **kwargs)\n",
    "        conn.close()\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(source='csv', filepath='/Users/003/Desktop/CalTech AI/4 - Machine Learning/Datasets - Machine Learning/Lesson_04_Regression_and_Its_Applications/4.11_Data_Preparation_Model_Building_and_Performance_Evaluation/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Copy vs. Shallow Copy\n",
    "\n",
    "![Copy](https://ibaibhavsingh.wordpress.com/wp-content/uploads/2016/09/screen-shot-2016-09-03-at-4-06-34-pm.png)\n",
    "\n",
    "<img src = 'Shallow vs Deep.png'>\n",
    "\n",
    "https://www.geeksforgeeks.org/difference-between-shallow-and-deep-copy-of-a-class/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "df_copy = deepcopy(df) #Deepcopy of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(df):\n",
    "    \"\"\"\n",
    "    Perform a comprehensive inspection of the loaded data.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame to be inspected.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Example usage:\n",
    "        # Load data into a DataFrame (replace 'data.csv' with your data file)\n",
    "        df = pd.read_csv('data.csv')\n",
    "\n",
    "        # Perform a comprehensive inspection of the loaded data\n",
    "        inspect_data(df)\n",
    "    \"\"\"\n",
    "    print(\"Data Inspection Report:\")\n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    # 1. Basic Information\n",
    "    print(\"\\n1. Basic Information:\")\n",
    "    display(df.head())\n",
    "    display(df.tail())\n",
    "    print(df.info())\n",
    "\n",
    "    # 2. Summary Statistics\n",
    "    print(\"\\n2. Summary Statistics:\")\n",
    "    numerical_df = df.select_dtypes(include=np.number)\n",
    "    summary_stats = numerical_df.describe(include='all').T\n",
    "    mode_values = numerical_df.mode().T\n",
    "    median_values = numerical_df.median().T\n",
    "    variance_values = numerical_df.var().T\n",
    "    summary_stats['mode'] = mode_values[0]\n",
    "    summary_stats['median'] = median_values\n",
    "    summary_stats['variance'] = variance_values\n",
    "    display(summary_stats)\n",
    "    print(\"\\n2. Categorical Summary Statistics:\")\n",
    "    display(df.describe(include=['O']))\n",
    "    \n",
    "    # 3. Missing Values\n",
    "    print(\"\\n3. Missing Values:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() == 0:\n",
    "        print(\"No missing values found.\")\n",
    "    else:\n",
    "        display(missing_values)\n",
    "    \n",
    "    # 4. Duplicate Rows\n",
    "    print(\"\\n4. Duplicate Rows:\")\n",
    "    num_duplicates = df.duplicated().sum()\n",
    "    if num_duplicates == 0:\n",
    "        print(\"No duplicate rows found.\")\n",
    "    else:\n",
    "        print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "    \n",
    "    # 5. Outliers\n",
    "    print(\"\\n5. Outliers:\")\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "    for col in numerical_cols:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f\"Boxplot of {col}\")\n",
    "        plt.show()\n",
    "    \n",
    "    # 6. Data Distribution\n",
    "    print(\"\\n6. Data Distribution:\")\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "    for col in categorical_cols:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        df[col].value_counts().plot(kind='bar')\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.show()\n",
    "    \n",
    "    # 7. Data Quality Metrics (Additional)\n",
    "    print(\"\\n7. Additional Data Quality Metrics:\")\n",
    "    # Calculate additional data quality metrics as needed\n",
    "    \n",
    "    # 8. Feature Engineering (Additional)\n",
    "    print(\"\\n8. Feature Engineering:\")\n",
    "    # Review newly engineered features as needed\n",
    "    \n",
    "    # 9. Data Imbalance (Additional)\n",
    "    print(\"\\n9. Data Imbalance:\")\n",
    "    # Check for class imbalances in classification tasks as needed\n",
    "    \n",
    "    # 10. Data Schema and Metadata (Additional)\n",
    "    print(\"\\n10. Data Schema and Metadata:\")\n",
    "    # Inspect data schema and metadata as needed\n",
    "    \n",
    "    # 11. Documentation and Annotations (Additional)\n",
    "    print(\"\\n11. Documentation and Annotations:\")\n",
    "    # Review documentation and annotations as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_and_optimize_data_types(df):\n",
    "    \"\"\"\n",
    "    Inspect the data and convert data types based on user inputs for maximum memory efficiency.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame to be inspected and optimized.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with optimized data types.\n",
    "\n",
    "    Example usage:\n",
    "        # Load data into a DataFrame (replace 'data.csv' with your data file)\n",
    "        df = pd.read_csv('data.csv')\n",
    "\n",
    "        # Inspect and optimize data types based on user inputs\n",
    "        optimized_df = inspect_and_optimize_data_types(df)\n",
    "    \"\"\"\n",
    "    # Get memory usage before optimization\n",
    "    memory_before = df.memory_usage(deep=True).sum() / (1024**2)  # Convert bytes to megabytes\n",
    "\n",
    "    # Inspect the data types of columns\n",
    "    print(\"Initial Data Types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # User input to select data types to convert\n",
    "    print(\"\\nSelect data types to convert:\")\n",
    "    print(\"1. Integer\")\n",
    "    print(\"2. Floating-point\")\n",
    "    print(\"3. Object (String)\")\n",
    "    print(\"4. Categorical (String with limited unique values)\")\n",
    "    selected_types = input(\"Enter the numbers separated by commas (e.g., '1,2,4'): \").split(',')\n",
    "    selected_types = [int(i) for i in selected_types]\n",
    "\n",
    "    # User input to select columns for conversion\n",
    "    print(\"\\nSelect columns to convert (or enter 'all' to convert all columns):\")\n",
    "    print(df.columns)\n",
    "    columns_to_convert = input(\"Enter column names separated by commas (or 'all'): \").split(',')\n",
    "    columns_to_convert = [col.strip() for col in columns_to_convert]\n",
    "\n",
    "    # Convert data types based on user inputs\n",
    "    for data_type in selected_types:\n",
    "        if data_type == 1:  # Integer\n",
    "            if columns_to_convert[0] == 'all':\n",
    "                int_cols = df.select_dtypes(include=['int']).columns\n",
    "            else:\n",
    "                int_cols = [col for col in columns_to_convert if col in df.columns]\n",
    "            for col in int_cols:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif data_type == 2:  # Floating-point\n",
    "            if columns_to_convert[0] == 'all':\n",
    "                float_cols = df.select_dtypes(include=['float']).columns\n",
    "            else:\n",
    "                float_cols = [col for col in columns_to_convert if col in df.columns]\n",
    "            for col in float_cols:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif data_type == 3:  # Object (String)\n",
    "            if columns_to_convert[0] == 'all':\n",
    "                object_cols = df.select_dtypes(include=['object']).columns\n",
    "            else:\n",
    "                object_cols = [col for col in columns_to_convert if col in df.columns]\n",
    "            for col in object_cols:\n",
    "                df[col] = df[col].astype('category')\n",
    "        elif data_type == 4:  # Categorical (String with limited unique values)\n",
    "            if columns_to_convert[0] == 'all':\n",
    "                object_cols = df.select_dtypes(include=['object']).columns\n",
    "            else:\n",
    "                object_cols = [col for col in columns_to_convert if col in df.columns]\n",
    "            for col in object_cols:\n",
    "                num_unique_values = len(df[col].unique())\n",
    "                num_total_values = len(df[col])\n",
    "                if num_unique_values / num_total_values < 0.5:  # Adjust the threshold as needed\n",
    "                    df[col] = df[col].astype('category')\n",
    "\n",
    "    # Get memory usage after optimization\n",
    "    memory_after = df.memory_usage(deep=True).sum() / (1024**2)  # Convert bytes to megabytes\n",
    "\n",
    "    print(\"\\nData Types After Optimization:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\nMemory Usage Before Optimization: {:.2f} MB\".format(memory_before))\n",
    "    print(\"Memory Usage After Optimization: {:.2f} MB\".format(memory_after))\n",
    "    print(\"Memory Usage Reduction: {:.2f}%\".format((1 - memory_after / memory_before) * 100))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection\n",
    "1. z-score\n",
    "2. percentile\n",
    "3. IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   age             32561 non-null  int32   \n",
      " 1   workclass       32561 non-null  category\n",
      " 2   fnlwgt          32561 non-null  int32   \n",
      " 3   education       32561 non-null  category\n",
      " 4   education.num   32561 non-null  int32   \n",
      " 5   marital.status  32561 non-null  category\n",
      " 6   occupation      32561 non-null  category\n",
      " 7   relationship    32561 non-null  category\n",
      " 8   race            32561 non-null  category\n",
      " 9   sex             32561 non-null  category\n",
      " 10  capital.gain    32561 non-null  int32   \n",
      " 11  capital.loss    32561 non-null  int32   \n",
      " 12  hours.per.week  32561 non-null  int32   \n",
      " 13  native.country  32561 non-null  category\n",
      " 14  income          32561 non-null  category\n",
      "dtypes: category(9), int32(6)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workclass', 'education', 'marital.status', 'occupation',\n",
       "       'relationship', 'race', 'sex', 'native.country', 'income'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Score on Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from copy import deepcopy\n",
    "\n",
    "dfz = deepcopy(df) #make a deep copy (for Z-score)\n",
    "\n",
    "for col in num_col:\n",
    "    dfz['stats.zscore'] = stats.zscore(dfz[col])\n",
    "    threshold = 3\n",
    "    dfz['outliers'] = np.where((dfz['stats.zscore'] - threshold > 0), True, np.where(dfz['stats.zscore'] + threshold < 0, True, False))\n",
    "    dfz.drop((dfz[dfz['outliers'] == True]).index, inplace=True)\n",
    "    dfz.drop(['outliers', 'stats.zscore'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% Data Remains - After Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.61 %\n"
     ]
    }
   ],
   "source": [
    "print(round((dfz.shape[0]/32561)*100, 2),'%') #Pass in dataframe and use total rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Approx 9% Dropped, If Threshold = 2, We Lose 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentile on Numeric Columns - YOU SELECT LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "dfq = deepcopy(df) #make a deep copy (for quartiles)\n",
    "\n",
    "for col in num_col:\n",
    "    upper_limit = dfq[col].quantile(0.98) #select upperlimit\n",
    "    lower_limit = dfq[col].quantile(0.02) #select lower limit\n",
    "    dfq[col] = np.where(dfq[col] < lower_limit, lower_limit, dfq[col])\n",
    "    dfq[col] = np.where(dfq[col] > upper_limit, upper_limit, dfq[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% Data Remains - After Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(round((dfq.shape[0]/32561)*100, 2),'%') #Pass in dataframe and use total rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Didn't Change!, Theoretically Would Choose Outliers That Would Cause Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe by Dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = df.select_dtypes(include=np.number).columns # selects all the numerical columns\n",
    "cat_col = df.select_dtypes(include='category').columns # Selects all the categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand Options in Categories - Determine if Ordinal, One-Hot, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass          9\n",
       "education         16\n",
       "marital.status     7\n",
       "occupation        15\n",
       "relationship       6\n",
       "race               5\n",
       "sex                2\n",
       "native.country    42\n",
       "income             2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.select_dtypes(include='category').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Don't use one-hot/dummies or else you'll have large amount of columns (41 for native.country, 15 and 14 added for education and occupation, respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoder(data): #function created, especially since we are applying to multiple dataframes that we want to pass in\n",
    "    \"\"\"It Label encodes every categorical column ie. converts categories into numbers and returns the modified dataframe\"\"\"\n",
    "    \n",
    "    for col in data.select_dtypes(include='category').columns:\n",
    "        #Instantiate\n",
    "        encoder = LabelEncoder()\n",
    "        #Fit + Transform\n",
    "        data[col] = encoder.fit_transform(data[col])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Pass in our dataframes\n",
    "df = label_encoder(df) #regular\n",
    "dfz = label_encoder(dfz) #z-score treated\n",
    "dfq = label_encoder(dfq) #quantile treated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>77053</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>132870</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>186061</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>140359</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>264663</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education.num  marital.status  \\\n",
       "0   90          0   77053         11              9               6   \n",
       "1   82          4  132870         11              9               6   \n",
       "2   66          0  186061         15             10               6   \n",
       "3   54          4  140359          5              4               0   \n",
       "4   41          4  264663         15             10               5   \n",
       "\n",
       "   occupation  relationship  race  sex  capital.gain  capital.loss  \\\n",
       "0           0             1     4    0             0          4356   \n",
       "1           4             1     4    0             0          4356   \n",
       "2           0             4     2    0             0          4356   \n",
       "3           7             4     4    0             0          3900   \n",
       "4          10             3     4    0             0          3900   \n",
       "\n",
       "   hours.per.week  native.country  income  \n",
       "0              40              39       0  \n",
       "1              18              39       0  \n",
       "2              40              39       0  \n",
       "3              40              39       0  \n",
       "4              40              39       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Categrical Variables\n",
    "- Seasons, Holiday, Functioning Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Date                       8760 non-null   datetime64[ns]\n",
      " 1   Rented Bike Count          8760 non-null   int32         \n",
      " 2   Hour                       8760 non-null   int32         \n",
      " 3   Temperature(°C)            8760 non-null   float32       \n",
      " 4   Humidity(%)                8760 non-null   int32         \n",
      " 5   Wind speed (m/s)           8760 non-null   float32       \n",
      " 6   Visibility (10m)           8760 non-null   int32         \n",
      " 7   Dew point temperature(°C)  8760 non-null   float32       \n",
      " 8   Solar Radiation (MJ/m2)    8760 non-null   float32       \n",
      " 9   Rainfall(mm)               8760 non-null   float32       \n",
      " 10  Snowfall (cm)              8760 non-null   float32       \n",
      " 11  Seasons                    8760 non-null   category      \n",
      " 12  Holiday                    8760 non-null   category      \n",
      " 13  Functioning Day            8760 non-null   category      \n",
      "dtypes: category(3), datetime64[ns](1), float32(6), int32(4)\n",
      "memory usage: 436.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #Look for your categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No Holiday', 'Holiday']\n",
       "Categories (2, object): ['Holiday', 'No Holiday']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Yes', 'No']\n",
       "Categories (2, object): ['No', 'Yes']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Winter', 'Spring', 'Summer', 'Autumn']\n",
       "Categories (4, object): ['Autumn', 'Spring', 'Summer', 'Winter']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['Holiday'].unique())\n",
    "display(df['Functioning Day'].unique())\n",
    "display(df['Seasons'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Holiday\n",
       "No Holiday    8328\n",
       "Holiday        432\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Functioning Day\n",
       "Yes    8465\n",
       "No      295\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Seasons\n",
       "Spring    2208\n",
       "Summer    2208\n",
       "Autumn    2184\n",
       "Winter    2160\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['Holiday'].value_counts())\n",
    "display(df['Functioning Day'].value_counts())\n",
    "display(df['Seasons'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8328\n",
       "0     432\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    8465\n",
       "0     295\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    2208\n",
       "2    2208\n",
       "0    2184\n",
       "3    2160\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['Holiday'].cat.codes.value_counts())\n",
    "display(df['Functioning Day'].cat.codes.value_counts())\n",
    "display(df['Seasons'].cat.codes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want it to be Reversed for Holiday! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Holiday'] = df['Holiday'].apply(lambda x: 0 if x == 'No Holiday' else 1)\n",
    "df['Functioning Day'] = df['Functioning Day'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "dummies = pd.get_dummies(df['Seasons'], drop_first=True) #drop_first drops first category to avoid multicollinearity (drops 1 of the seasons as it will be implicitly represented)\n",
    "dummies = dummies.astype(int) #in case get_dummies gives you boolean (otherwise it should default)\n",
    "df = pd.concat([df.drop('Seasons', axis=1), dummies], axis=1) #remove original 'Seasons' column, merge dummy variables with remaining DataFrame along the columns axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['ChestPain', 'Thal'], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIRM THAT IT WORKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>1003</td>\n",
       "      <td>19</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1894</td>\n",
       "      <td>-10.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>764</td>\n",
       "      <td>20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-9.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>694</td>\n",
       "      <td>21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>39</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>-9.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1859</td>\n",
       "      <td>-9.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>584</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "      <td>43</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1909</td>\n",
       "      <td>-9.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "0    2017-12-01                254     0             -5.2           37   \n",
       "1    2017-12-01                204     1             -5.5           38   \n",
       "2    2017-12-01                173     2             -6.0           39   \n",
       "3    2017-12-01                107     3             -6.2           40   \n",
       "4    2017-12-01                 78     4             -6.0           36   \n",
       "...         ...                ...   ...              ...          ...   \n",
       "8755 2018-11-30               1003    19              4.2           34   \n",
       "8756 2018-11-30                764    20              3.4           37   \n",
       "8757 2018-11-30                694    21              2.6           39   \n",
       "8758 2018-11-30                712    22              2.1           41   \n",
       "8759 2018-11-30                584    23              1.9           43   \n",
       "\n",
       "      Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "0                  2.2              2000                 -17.600000   \n",
       "1                  0.8              2000                 -17.600000   \n",
       "2                  1.0              2000                 -17.700001   \n",
       "3                  0.9              2000                 -17.600000   \n",
       "4                  2.3              2000                 -18.600000   \n",
       "...                ...               ...                        ...   \n",
       "8755               2.6              1894                 -10.300000   \n",
       "8756               2.3              2000                  -9.900000   \n",
       "8757               0.3              1968                  -9.900000   \n",
       "8758               1.0              1859                  -9.800000   \n",
       "8759               1.3              1909                  -9.300000   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Holiday  \\\n",
       "0                         0.0           0.0            0.0       0   \n",
       "1                         0.0           0.0            0.0       0   \n",
       "2                         0.0           0.0            0.0       0   \n",
       "3                         0.0           0.0            0.0       0   \n",
       "4                         0.0           0.0            0.0       0   \n",
       "...                       ...           ...            ...     ...   \n",
       "8755                      0.0           0.0            0.0       0   \n",
       "8756                      0.0           0.0            0.0       0   \n",
       "8757                      0.0           0.0            0.0       0   \n",
       "8758                      0.0           0.0            0.0       0   \n",
       "8759                      0.0           0.0            0.0       0   \n",
       "\n",
       "     Functioning Day  Spring  Summer  Winter  \n",
       "0                  1       0       0       1  \n",
       "1                  1       0       0       1  \n",
       "2                  1       0       0       1  \n",
       "3                  1       0       0       1  \n",
       "4                  1       0       0       1  \n",
       "...              ...     ...     ...     ...  \n",
       "8755               1       0       0       0  \n",
       "8756               1       0       0       0  \n",
       "8757               1       0       0       0  \n",
       "8758               1       0       0       0  \n",
       "8759               1       0       0       0  \n",
       "\n",
       "[8760 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Date                       8760 non-null   datetime64[ns]\n",
      " 1   Rented Bike Count          8760 non-null   int32         \n",
      " 2   Hour                       8760 non-null   int32         \n",
      " 3   Temperature(°C)            8760 non-null   float32       \n",
      " 4   Humidity(%)                8760 non-null   int32         \n",
      " 5   Wind speed (m/s)           8760 non-null   float32       \n",
      " 6   Visibility (10m)           8760 non-null   int32         \n",
      " 7   Dew point temperature(°C)  8760 non-null   float32       \n",
      " 8   Solar Radiation (MJ/m2)    8760 non-null   float32       \n",
      " 9   Rainfall(mm)               8760 non-null   float32       \n",
      " 10  Snowfall (cm)              8760 non-null   float32       \n",
      " 11  Holiday                    8760 non-null   category      \n",
      " 12  Functioning Day            8760 non-null   category      \n",
      " 13  Spring                     8760 non-null   int32         \n",
      " 14  Summer                     8760 non-null   int32         \n",
      " 15  Winter                     8760 non-null   int32         \n",
      "dtypes: category(2), datetime64[ns](1), float32(6), int32(7)\n",
      "memory usage: 530.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Inspecting\n",
    "* Unique Values and Number of Unique Values\n",
    "* Missing\n",
    "* Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def calculate_data_quality_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculate additional data quality metrics for the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing data quality metrics.\n",
    "\n",
    "    Example usage:\n",
    "        # Load data into a DataFrame (replace 'data.csv' with your data file)\n",
    "        df = pd.read_csv('data.csv')\n",
    "\n",
    "        # Calculate additional data quality metrics\n",
    "        quality_metrics = calculate_data_quality_metrics(df)\n",
    "        print(\"Additional Data Quality Metrics:\")\n",
    "        print(quality_metrics)\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: Percentage of non-null values for each column\n",
    "    completeness = df.notnull().mean() * 100\n",
    "    metrics['completeness'] = completeness\n",
    "\n",
    "    # Accuracy: For categorical columns, percentage of unique values that are correct\n",
    "    accuracy = {}\n",
    "    categorical_cols = df.select_dtypes(include='object').columns\n",
    "    for col in categorical_cols:\n",
    "        accuracy[col] = df[col].nunique() / df[col].notnull().sum() * 100\n",
    "    metrics['accuracy'] = accuracy\n",
    "\n",
    "    # Consistency: Percentage of unique values that are consistent across different columns\n",
    "    consistency = {}\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Consider only categorical columns\n",
    "            unique_values = df[col].unique()\n",
    "            consistent_values = sum(df.apply(lambda x: x[col] in unique_values, axis=1)) / len(df) * 100\n",
    "            consistency[col] = consistent_values\n",
    "    metrics['consistency'] = consistency\n",
    "\n",
    "    # Timeliness: Percentage of recent data points compared to the total number of data points\n",
    "    # (This metric may not be applicable to all datasets)\n",
    "    # Example: if there's a date column, you can calculate the percentage of data points within the last year\n",
    "    timeliness = None  # Add implementation as needed\n",
    "    metrics['timeliness'] = timeliness\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Data Quality Metrics:\n",
      "{   'accuracy': {   'Cabin': 72.05882352941177,\n",
      "                    'Embarked': 0.3374578177727784,\n",
      "                    'Name': 100.0,\n",
      "                    'Sex': 0.22446689113355783,\n",
      "                    'Ticket': 76.43097643097643},\n",
      "    'completeness': PassengerId    100.000000\n",
      "Survived       100.000000\n",
      "Pclass         100.000000\n",
      "Name           100.000000\n",
      "Sex            100.000000\n",
      "Age             80.134680\n",
      "SibSp          100.000000\n",
      "Parch          100.000000\n",
      "Ticket         100.000000\n",
      "Fare           100.000000\n",
      "Cabin           22.895623\n",
      "Embarked        99.775533\n",
      "dtype: float64,\n",
      "    'consistency': {   'Cabin': 22.895622895622896,\n",
      "                       'Embarked': 99.77553310886644,\n",
      "                       'Name': 100.0,\n",
      "                       'Sex': 100.0,\n",
      "                       'Ticket': 100.0},\n",
      "    'timeliness': None}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "quality_metrics = calculate_data_quality_metrics(df)\n",
    "print(\"Additional Data Quality Metrics:\")\n",
    "pp.pprint(quality_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Cleaning & Preparation\n",
    "* Need to Add\n",
    "    * Handling Missing in Multiple Ways: dropna, fillna\n",
    "    * Different Data Formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix DType: Datetime, Categorical, Float/Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dtype():\n",
    "    \"\"\"This is a static function that reduces memory consuption by converting objects \n",
    "    to category and int64 -> int8, float64 -> float16\n",
    "    \n",
    "    Returns an optimized DF\"\"\"\n",
    "    print('Printing out categorical variables and the values \\n\\n')\n",
    "    for col in df.columns:\n",
    "        if col == 'Date':\n",
    "            df[col] = pd.to_datetime(df[col],format='%d/%m/%Y')\n",
    "        elif df[col].dtype == 'O':\n",
    "            print(\"    \", col, df[col].unique())\n",
    "            df[col] = pd.Categorical(df[col])\n",
    "        elif df[col].dtype == 'float64':\n",
    "             df[col] = df[col].astype('float32') #interestingly if used 'float16' it would return \"inf\" in your df.describe().T in T mean (so changed to float32)\n",
    "        elif df[col].dtype == 'int64':\n",
    "             df[col] = df[col].astype('int32')       \n",
    "        \n",
    "fix_dtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates, Missing, Standardized String Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, tasks):\n",
    "    \"\"\"\n",
    "    Perform selected data cleaning tasks on a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame to be cleaned.\n",
    "        tasks (list): A list of strings representing the cleaning tasks to be performed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    cleaned_df = df.copy()\n",
    "\n",
    "    for task in tasks:\n",
    "        if task == 'remove_duplicates':\n",
    "            cleaned_df = remove_duplicates(cleaned_df)\n",
    "        elif task == 'handle_missing_values':\n",
    "            cleaned_df = handle_missing_values(cleaned_df)\n",
    "        elif task == 'standardize_data_formats':\n",
    "            cleaned_df = standardize_data_formats(cleaned_df)\n",
    "        else:\n",
    "            print(f\"Warning: Unknown task '{task}'\")\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Remove duplicate rows from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with duplicate rows removed.\n",
    "    \"\"\"\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    \"\"\"\n",
    "    Handle missing values in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with missing values handled.\n",
    "    \"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "def standardize_data_formats(df):\n",
    "    \"\"\"\n",
    "    Standardize data formats in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with standardized data formats.\n",
    "    \"\"\"\n",
    "    string_columns = df.select_dtypes(include='object').columns\n",
    "    df[string_columns] = df[string_columns].apply(lambda x: x.str.lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask user for cleaning tasks\n",
    "selected_tasks = []\n",
    "print(\"Available cleaning tasks:\")\n",
    "print(\"1. Remove duplicates\")\n",
    "print(\"2. Handle missing values\")\n",
    "print(\"3. Standardize data formats\")\n",
    "while True:\n",
    "    task = input(\"Enter the number of the cleaning task you want to perform (or 'done' to finish): \")\n",
    "    if task.lower() == 'done':\n",
    "        break\n",
    "    elif task == '1':\n",
    "        selected_tasks.append('remove_duplicates')\n",
    "    elif task == '2':\n",
    "        selected_tasks.append('handle_missing_values')\n",
    "    elif task == '3':\n",
    "        selected_tasks.append('standardize_data_formats')\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter a valid task number.\")\n",
    "\n",
    "# Clean the data based on selected tasks\n",
    "cleaned_df = clean_data(df, selected_tasks)\n",
    "print(\"Data cleaning completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect After Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
